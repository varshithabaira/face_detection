{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1073efc7-f117-4064-9909-bf63ee5dc0fa",
   "metadata": {},
   "source": [
    "# Mediapipe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce68b3aa-7e58-432c-a6e3-8f527629aa03",
   "metadata": {},
   "source": [
    "## Mediapipe is a frame work which helps to process img, video ,audio and other media in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2007d23c-8fc2-498a-b744-2df1df6a4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp \n",
    "import cv2 \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bd86ac2-4922-4f2e-b947-ab8e2be6e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.solutions   #It is a pre built module.It takes the input as img or video and gives the output as detecting face,hand. \n",
    "\n",
    "fd= mp.solutions.face_detection   # it is a module\n",
    "\n",
    "face_detection_model = fd.FaceDetection(min_detection_confidence=0.5, model_selection=0)  # It is used to initialize a face detection from mediapipe\n",
    "\n",
    "img = cv2.imread(r\"C:\\Users\\Varshitha\\Pictures\\Screenshots\\Screenshot 2025-05-16 165817.png\") \n",
    "\n",
    "rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)  # we have to convert the img from BGR to RGB because mediapipe models are trained to work with RGB\n",
    "\n",
    "output = face_detection_model.process(rgb)  # It is to run the face detection model on the input image ans get the detection result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1b997b5-0d11-4a38-9362-6d40130a358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r\"C:\\Users\\Varshitha\\Pictures\\Screenshots\\Screenshot 2025-05-16 165817.png\")\n",
    "\n",
    "mp.solutions.drawing_utils.draw_detection(image=img,detection=output.detections[0]\n",
    "                                          ,keypoint_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(color=(0,0,255),thickness=2,circle_radius = 2)\n",
    "                                          ,bbox_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ef3de6b-b589-46e9-8ae1-73242e7c620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"face detection\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d51d776-5a3a-4c73-8dc0-ffd7dcf1f2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0404512-c647-4fd3-9d30-1403e1068ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
